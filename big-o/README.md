# Big-O

## Big-O Intro

Suppose we have two functions, codes, scripts, or algorithms, how do we know which one is better?

They both accomplish the same thing but they are written differently.

Big-O notation is a way to mathematically figure out which of the two is better, which one runs more efficiently.

Normally, we would want to use the one that runs faster.

This is called time complexity. We don't measure time complexity in time but in the number of operations. The reason we do this is because time can vary based on the machine, the environment, and other factors. What doesn't change is the number of operations. Thus, the time complexity on either machine will be the same.

Time complexity is a way to measure how long an algorithm takes to run as the input size grows.

Also, we can measure space complexity. This is how much memory an algorithm uses as the input size grows.
